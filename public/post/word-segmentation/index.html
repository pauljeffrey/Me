<!DOCTYPE html>
<html lang=""><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>Unraveling the Secrets of Raw Text: A Journey Through Word, Sentence Segmentation and Capitalization with Python (Part 1) | Jeffrey Paul</title>
    <meta name="description" content="Unraveling the Secrets of Raw Text: A Journey Through Word, Sentence Segmentation and Capitalization with Python (Part 1)">
    <meta property="og:site_name" content="Unraveling the Secrets of Raw Text: A Journey Through Word, Sentence Segmentation and Capitalization with Python (Part 1)" />
    <meta property="og:title" content="Jeffrey Paul" />
    <meta property="og:description" content="Title: Unraveling the Secrets of Raw Text: A Journey Through Word, Sentence Segmentation and Capitalization with Python (Part 1) Introduction In the realm of Natural Language Processing (NLP), engineers/data scientist can sometimes be faced with raw, unprocessed text which may present a unique challenge. Unlike structured or clean data, raw text may lack word boundaries, sentence boundaries, and proper noun identification. It&amp;rsquo;s a jumbled mess of letters that can leave even the most seasoned NLP engineer scratching their heads." />
    <meta property="og:image" content="http://localhost:1313/images/jeff2.jpg" />
    <meta name="keywords"
          content="" />
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
        integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
          crossorigin="anonymous">

    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
        integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
        crossorigin="anonymous">
    </script>

    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
        integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);">
    </script>
    
    <meta name="keywords" content="fast, hugo, theme, minimal, gruvbox">
    <link rel="icon" type="image/svg" href='http://localhost:1313/img/logo.png' />
    <meta name="author" content='Jeffrey Paul'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.124.1">
    
    <link rel="stylesheet" href="http://localhost:1313/sass/main.min.a669fc379ca0ba4d389af69be2682407e7bca16d368f2e7ad5b83c0cd80029b3.css" type="text/css" media="screen">

    

    

    
    </head>
<body>
      <div class="line" id="scrollIndicator"></div>
      <div class="main"><div class="title">
  <div class="name">
    <h2><a href="http://localhost:1313/"
	   style="text-decoration: none; color: inherit;">Jeffrey Paul</a></h2>
  </div>
  <div class="color-scheme">
    <input type="checkbox" class="checkbox" id="chk" />
    <label class="label" for="chk">
						<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="moon" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M283.211 512c78.962 0 151.079-35.925 198.857-94.792 7.068-8.708-.639-21.43-11.562-19.35-124.203 23.654-238.262-71.576-238.262-196.954 0-72.222 38.662-138.635 101.498-174.394 9.686-5.512 7.25-20.197-3.756-22.23A258.156 258.156 0 0 0 283.211 0c-141.309 0-256 114.511-256 256 0 141.309 114.511 256 256 256z"></path></svg>
						<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="sun" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 160c-52.9 0-96 43.1-96
										96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96zm246.4 80.5l-94.7-47.3 33.5-100.4c4.5-13.6-8.4-26.5-21.9-21.9l-100.4 33.5-47.4-94.8c-6.4-12.8-24.6-12.8-31 0l-47.3 94.7L92.7 70.8c-13.6-4.5-26.5 8.4-21.9 21.9l33.5 100.4-94.7 47.4c-12.8 6.4-12.8 24.6 0 31l94.7 47.3-33.5 100.5c-4.5 13.6 8.4 26.5 21.9 21.9l100.4-33.5 47.3 94.7c6.4 12.8 24.6 12.8 31 0l47.3-94.7 100.4 33.5c13.6 4.5 26.5-8.4 21.9-21.9l-33.5-100.4 94.7-47.3c13-6.5 13-24.7.2-31.1zm-155.9 106c-49.9 49.9-131.1 49.9-181 0-49.9-49.9-49.9-131.1 0-181 49.9-49.9 131.1-49.9 181 0 49.9 49.9 49.9 131.1 0 181z"></path></svg>
      <div class="ball"></div>
    </label>
  </div>
</div>
<script>
  const themeSetter = (theme) => {
      document.body.classList.toggle('dark')
      localStorage.setItem('theme', theme)
      blockSwitcher()
  }

  const blockSwitcher = () => [...document.getElementsByTagName("BLOCKQUOTE")]
	.forEach(b => b.classList.toggle('dark'))

  const styleSwapper = () => {
      document.body.classList.add('back-transition')
      if (localStorage.getItem('theme') === 'dark') themeSetter('light')
      else if (localStorage.getItem('theme') === 'light') themeSetter('dark')
  }

  if (localStorage.getItem('theme') === 'dark'){
      themeSetter('dark')
      document.addEventListener("DOMContentLoaded", blockSwitcher)
  }
 else localStorage.setItem('theme', 'light')

  document.getElementById('chk').addEventListener('change',styleSwapper);

  window.addEventListener("scroll", () => {
      let height = document.documentElement.scrollHeight
          - document.documentElement.clientHeight;
      if(height >= 500){
	  let winScroll = document.body.scrollTop
              || document.documentElement.scrollTop;
	  let scrolled = (winScroll / height) * 100;
	  document.getElementById("scrollIndicator").style.width = scrolled + "%";
      }
  });
</script>

<section class="intro">
  
  <div class="post-header">
    <a class="go-back" href="http://localhost:1313/"><svg aria-hidden="true" focusable="false" data-prefix="far" class="back-icon" data-icon="caret-square-left" height="25px" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M272 157.1v197.8c0 10.7-13 16.1-20.5 8.5l-98.3-98.9c-4.7-4.7-4.7-12.2 0-16.9l98.3-98.9c7.5-7.7 20.5-2.3 20.5 8.4zM448 80v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V80c0-26.5 21.5-48 48-48h352c26.5 0 48 21.5 48 48zm-48 346V86c0-3.3-2.7-6-6-6H54c-3.3 0-6 2.7-6 6v340c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"></path></svg> </a>
    <h2 class="post-title">Unraveling the Secrets of Raw Text: A Journey Through Word, Sentence Segmentation and Capitalization with Python (Part 1)</h2>
</div>

<p>By <a href="">Paul Jeffrey</a></p>

<p class="post-dets">Published on: February 3, 2024
  | Reading Time: 22 min | Last Modified: February 3, 2024
  <br>
</p>
<span class="tags">
  
  <h5><a class="tag" href='http://localhost:1313/tags/neural%20networks'>neural networks</a></h5>
  
  <h5><a class="tag" href='http://localhost:1313/tags/natural%20language%20processing'>natural language processing</a></h5>
  
  <h5><a class="tag" href='http://localhost:1313/tags/word%20segmentation'>word segmentation</a></h5>
  
</span>

<div class="content">
  <h1 id="title-unraveling-the-secrets-of-raw-text-a-journey-through-word-sentence-segmentation-and-capitalization-with-python-part-1">Title: Unraveling the Secrets of Raw Text: A Journey Through Word, Sentence Segmentation and Capitalization with Python (Part 1)</h1>
<h2 id="introduction">Introduction</h2>
<p>In the realm of Natural Language Processing (NLP), engineers/data scientist can sometimes be faced with raw, unprocessed text which may present a unique challenge. Unlike structured or clean data, raw text may lack word boundaries, sentence boundaries, and proper noun identification. It&rsquo;s a jumbled mess of letters that can leave even the most seasoned NLP engineer scratching their heads.</p>
<p>But fear not, for I embarked on a captivating journey to develop a machine learning system that transforms this unstructured chaos into comprehensible, well-demarcated words and sentences. Through the magic of word segmentation, sentence segmentation, and capitalization, this system achieved an astonishing accuracy of approximately 97%! For this task, we will be making use of the brown corpus from the NLTK library.</p>
<p>This is the first of a series of 3 articles and all are interdependent. Here is a summary of what we want to achieve below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Raw text</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;danmorgantoldhimselfhewouldforgetannturnerhewaswellridofherhecertainlydidn&#39;twantawifewhowasfickleasannifhehadmarriedherhe&#39;dhavebeenaskingfortroublebutallofthiswasrationalizationsometime...&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Final output</span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;dan morgan told himself he would forget ann turner he was well rid of her he certainly did n&#39;t want a wife who was fickle as ann if he had married her he &#39;d have been asking for trouble but all of this was rationalization sometime...&#34;</span>
</span></span></code></pre></div><p>Are you ready? Let&rsquo;s go!</p>
<h2 id="data-download">Data Download</h2>
<p>First, we import all the necessary libraries (we will be using tensorflow for our models here):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> MinMaxScaler
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline, FeatureUnion
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.base <span style="color:#f92672">import</span> BaseEstimator, TransformerMixin
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> OneHotEncoder,OrdinalEncoder
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pickle
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.callbacks <span style="color:#f92672">import</span> EarlyStopping
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> keras.callbacks <span style="color:#f92672">import</span> ReduceLROnPlateau
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras <span style="color:#f92672">import</span> Sequential
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Dense
</span></span></code></pre></div><p>Also, we will be making use of a small chunk of the brown text corpus found in the nltk library. We will remove all upper cases, sentence demarcations, word demarcations to get our raw text.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;brown&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> brown
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> matplotlib <span style="color:#f92672">import</span> pyplot
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;averaged_perceptron_tagger&#39;</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;universal_tagset&#39;</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;punkt&#39;</span>)
</span></span></code></pre></div><p>First, let&rsquo;s check out the number of words in the brown corpus:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Length of all words in all genres: &#39;</span>, len(brown<span style="color:#f92672">.</span>words()))
</span></span></code></pre></div><pre tabindex="0"><code>Length of all words in all genres:  1161192
</code></pre><p>Here, we see that there are more than 1 million words in all genre of the brown corpus. To model word segmentation, the list of characters will grow exponentially. Therefore, we will consider just a few number of genre to train our word segmentation model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># extract corpus for word segmentation training/sentence segmentation.</span>
</span></span><span style="display:flex;"><span>genres <span style="color:#f92672">=</span> brown<span style="color:#f92672">.</span>categories() <span style="color:#75715e"># get genre categories</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_corpus</span>(doc<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;char&#39;</span>,num_of_genre<span style="color:#f92672">=</span> <span style="color:#ae81ff">9</span>):
</span></span><span style="display:flex;"><span>  corpus <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span> <span style="color:#75715e">#extract words from all genre into this variable</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> doc <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;char&#39;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(num_of_genre):
</span></span><span style="display:flex;"><span>      corpus <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(brown<span style="color:#f92672">.</span>words(categories<span style="color:#f92672">=</span>genres[i]))
</span></span><span style="display:flex;"><span>      corpus <span style="color:#f92672">=</span> corpus<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;.&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>) 
</span></span><span style="display:flex;"><span>      corpus <span style="color:#f92672">=</span> corpus<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;,&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>) 
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> corpus
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    corpus <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(brown<span style="color:#f92672">.</span>words(categories<span style="color:#f92672">=</span>genres[i]))
</span></span><span style="display:flex;"><span>    corpus <span style="color:#f92672">=</span> corpus<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;.&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>)
</span></span><span style="display:flex;"><span>    corpus <span style="color:#f92672">=</span> corpus<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;,&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> corpus
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># extract Text</span>
</span></span><span style="display:flex;"><span>corpus <span style="color:#f92672">=</span> extract_corpus(num_of_genre<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>)
</span></span><span style="display:flex;"><span>print(len(corpus))
</span></span></code></pre></div><pre tabindex="0"><code>3817507
</code></pre><p>We will use this chunk to create our raw data.</p>
<h2 id="word-segmentation">Word Segmentation</h2>
<p>The first step in our quest is to tackle word segmentation. This involves breaking down the continuous stream of characters into individual words. It&rsquo;s like taking a jumbled puzzle and painstakingly piecing it together, one word at a time.</p>
<p>To accomplish this, we must create a model that can segment raw texts (continuous stream of characters) into individual words. Therefore, we need to create a training dataset to train this model.</p>
<p>By feeding the model with a sequence of characters and their corresponding features (such as part-of-speech tags), it learns to predict the boundaries between words.</p>
<p>To achieve this, we will create characters (in the order they occur in the raw data) and targets for each character in our raw data. The target labels will be as follows:</p>
<ul>
<li>S for single word</li>
<li>E for end of word</li>
<li>I for inside word</li>
<li>B for beginning of word.</li>
</ul>
<p>We could also add an extra tag for &rsquo;end of sentence&rsquo; if we consider a joint (word and sentence segmentation). we will store the training data in an array. Then, we shall model this problem as a classification problem where we map each character to its corresponding target as stated above.
Here is the code to handle all of this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>word_cat_targ <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;B&#39;</span> : <span style="color:#ae81ff">0</span>, <span style="color:#75715e">#</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;I&#39;</span> : <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;E&#39;</span> : <span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;S&#39;</span> : <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert target to categorical variables</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">to_cat</span>(targ, cat_target):
</span></span><span style="display:flex;"><span>  target <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> targ:
</span></span><span style="display:flex;"><span>    target<span style="color:#f92672">.</span>append(cat_target[i])
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(target)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_train_data</span>(corpus):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># if &#39; &#39; exists before and after, its a single word</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># if &#39; &#39; exists only after character then it marks end of word</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># if &#39; &#39; exists only before character then its the beginning of the word</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># if &#39; &#39; does not exist before or after the character, then character exists within a word.</span>
</span></span><span style="display:flex;"><span>  train_data <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  target_data <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  length <span style="color:#f92672">=</span> len(corpus)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> index,char <span style="color:#f92672">in</span> enumerate(corpus):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ignore space characters</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> char <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39; &#39;</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    train_data<span style="color:#f92672">.</span>append(char) <span style="color:#75715e"># append character</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> index <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:<span style="color:#75715e"># if beginning of corpus, tag character as &#39;B&#39;</span>
</span></span><span style="display:flex;"><span>      print(char)
</span></span><span style="display:flex;"><span>      target_data<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;B&#39;</span>)
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> index <span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">&lt;</span> length : <span style="color:#75715e"># If character is not the last character in the corpus</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">#if space precedes and supersedes character</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">if</span> corpus[index<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39; &#39;</span> <span style="color:#f92672">and</span> corpus[index<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39; &#39;</span>:
</span></span><span style="display:flex;"><span>        target_data<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;S&#39;</span>)
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># if space exist only before char</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">elif</span> corpus[index<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">==</span> <span style="color:#e6db74">&#39; &#39;</span> :
</span></span><span style="display:flex;"><span>        target_data<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;B&#39;</span>)
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># if space exists after character</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">elif</span> corpus[index<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39; &#39;</span>:
</span></span><span style="display:flex;"><span>        target_data<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;E&#39;</span>)
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># if no space before and after character</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">else</span> :
</span></span><span style="display:flex;"><span>        target_data<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;I&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># if last character in the corpus</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>      target_data<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;E&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> train_data, target_data
</span></span></code></pre></div><p>Let&rsquo;s generate the data:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train_data, target_data <span style="color:#f92672">=</span> create_train_data(corpus<span style="color:#f92672">.</span>lower())
</span></span><span style="display:flex;"><span>target_data <span style="color:#f92672">=</span> to_cat(target_data, word_cat_targ)
</span></span></code></pre></div><p>Next, we do a little analysis on the training data. We store it in a dataframe for easy analysis.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Characters&#39;</span>: train_data})
</span></span><span style="display:flex;"><span>train_data<span style="color:#f92672">.</span>tail()
</span></span></code></pre></div><!-- raw HTML omitted -->
<h3 id="models-objective">Model&rsquo;s Objective:</h3>
<p>Let&rsquo;s talk about the model a little. The task here is to classify each character of a sequence (raw text) as end of word E, beginning of word B, inside word I, single word S.</p>
<p>The major problem here is that these characters have no cues or have no features associated with them. Therefore, important features that will aid our model classify the characters accurately have to be generated.</p>
<h3 id="feature-extraction-and-engineering-">Feature Extraction and Engineering :</h3>
<p>We need to generate features that will increase the accuracy of the classification probability. We will consider the character itself and the properties of the sequence (n-gram) of characters before and after it.</p>
<p>Using this method, we get not only the feature representation of the index character, but also the contextual information (in what context the character was used ) since we consider the characters existing before and after it. In this project, we will consider the following characteristics for feature engineering:</p>
<ol>
<li>Features of the index character:</li>
</ol>
<ul>
<li>one hot encoding representation</li>
<li>type of char : letter, number, symbol (punctuation)</li>
<li>class of char : vowel ,consonant, punctuation (e.g &lsquo;!&rsquo;), sign (e.g &lsquo;$&rsquo;)</li>
</ul>
<ol start="2">
<li>Properties of each character associated/surrounding the index character (This will serve as the context (sequence pattern) for the index character):</li>
</ol>
<ul>
<li>One hot encoding representation</li>
<li>type of char</li>
<li>class of char</li>
</ul>
<ol start="3">
<li>
<p>properties of sequence pattern (i.e pre-character(s), index character,post-character(s)).
We consider the characters that occur before and after the index character. To this, we consider the following:</p>
</li>
<li>
<p>frequency of sequence pattern in corpus.</p>
</li>
<li>
<p>Transitional probability: This is the probability of transitioning into another non-space character given the index character. We shall look at this property in both forward and backward direction to capture the pre and post characters. This is an intuitive entity. If the likelihood of seeing another non-space character after a particular index character is high, it means that both characters (index and one after) are more likely to be part of a word and so there should be no space between them. If its low, it means its less likely that these characters exist together in a word and so should be separated by a space forming different words. It is calculated by :</p>
</li>
</ol>
<p>[ \text{Probability}(x, y) = \frac{\text{Frequency}(x \text{ and } y \text{ occurring together})}{\text{Frequency}(x)} ]</p>
<p>where:</p>
<ul>
<li>( x ) is the index character</li>
<li>( y ) is the pre or post-character</li>
</ul>
<p>we can also take this a step further by calculating the probability of a sequence of character transitioning into another character. For example, given the word &lsquo;dinner&rsquo;, we can consider the transitional probability of the sequence &lsquo;di&rsquo; transitioning into the letter &rsquo;n&rsquo;. The higher this probability, the more likely that these three letters are part of a word and should not be separated by a space.</p>
<p>[ \text{Probability}(\text{sequence} \rightarrow y) = \frac{\text{Frequency}(\text{sequence} \text{ followed by } y)}{\text{Frequency}(\text{sequence})} ]</p>
<ol start="6">
<li>probability of the sequence pattern : For example, the probability of the sequence pattern &rsquo;the&rsquo; given the corpus if we consider a tri-gram pattern (3 character sequence) is given by :</li>
</ol>
<p>[ \text{Probability}(\text{pattern}) = \frac{\text{Frequency}(\text{pattern})}{\text{Total number of characters in corpus}} ]</p>
<p>Another is:</p>
<p>[ \text{Probability}(\text{n-gram}) = \frac{\text{Frequency}(\text{n-gram})}{\text{Total number of occurring n-grams}} ]</p>
<ul>
<li>we may also consider the prob. of the class pattern of the sequence (e.g the character pattern &rsquo;the&rsquo; is a &lsquo;consonant consonant vowel&rsquo; pattern). It will be given by:</li>
</ul>
<p>[ \text{Probability}(\text{class pattern}) = \frac{\text{Frequency}(\text{class sequence})}{\text{Total number of sequence types}} ]</p>
<h4 id="note">Note:</h4>
<p>&rsquo;n-gram&rsquo; here refers to the character(s) before and after the current character. It was used here for convenience.</p>
<p>Since, the following models will be heavily reliant on frequencies and probabilities, the models will do way better with a large corpus! Secondly, text processing will definitely be slower here because it will take more time extracting these features from a large enough dataset. Therefore, we trade computation, time for better perfomance of the model in all tasks in this notebook.</p>
<p>Lets check out the unique characters in the dataset. We have 55 unique characters in the dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(len(train_data[<span style="color:#e6db74">&#39;Characters&#39;</span>]<span style="color:#f92672">.</span>unique()))
</span></span><span style="display:flex;"><span>train_data[<span style="color:#e6db74">&#39;Characters&#39;</span>]<span style="color:#f92672">.</span>unique()
</span></span></code></pre></div><p>Now, we write some functions that will convert the meaningful properties of each character into class label encoding. Also as said earlier , we will create context for each characters by creating columns for the set of characters (n-gram) that exist both before and after them. This can be likened to helping the model see the future and past characters before making a decision.</p>
<p>This gives an idea of the likelihood of this sequence of string being part of a word (using the frequency of occurence of the sequence pattern in the whole corpus.</p>
<p>We do this by shifting the columns (&lsquo;Character column&rsquo;) by a number of steps both up and down. We also use a custom label for all NaN values that appear in the newly created columns. This custom label will represent the null values.</p>
<p>For this first model, we use a &lsquo;UNK&rsquo; to represent null values. We also use an n_gram of 2. This means we will extract the 2 characters before and after every character.</p>
<p>Create function that generates n-gram characters preceding and superceding the index character. We will work with just 1 or 2 characters pre and post index character. The reason is because since we are using a one hot encoding representation, we do not want too much of a sparse matrix as data for our model. We first define vowels, consonants, punctuations and symbols.</p>
<pre tabindex="0"><code>array([&#39;d&#39;, &#39;a&#39;, &#39;n&#39;, &#39;m&#39;, &#39;o&#39;, &#39;r&#39;, &#39;g&#39;, &#39;t&#39;, &#39;l&#39;, &#39;h&#39;, &#39;i&#39;, &#39;s&#39;, &#39;e&#39;,
       &#39;f&#39;, &#39;w&#39;, &#39;u&#39;, &#39;c&#39;, &#39;y&#39;, &#34;&#39;&#34;, &#39;k&#39;, &#39;v&#39;, &#39;b&#39;, &#39;z&#39;, &#39;p&#39;, &#39;x&#39;, &#39;;&#39;,
       &#39;j&#39;, &#39;q&#39;, &#39;`&#39;, &#39;?&#39;, &#39;-&#39;, &#39;:&#39;, &#39;!&#39;, &#39;2&#39;, &#39;8&#39;, &#39;(&#39;, &#39;)&#39;, &#39;&amp;&#39;, &#39;3&#39;,
       &#39;0&#39;, &#39;1&#39;, &#39;9&#39;, &#39;5&#39;, &#39;$&#39;, &#39;6&#39;, &#39;7&#39;, &#39;4&#39;, &#39;%&#39;, &#39;[&#39;, &#39;]&#39;, &#39;/&#39;, &#39;*&#39;,
       &#39;+&#39;, &#39;{&#39;, &#39;}&#39;], dtype=object)
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vowels <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;a&#39;</span>,<span style="color:#e6db74">&#39;e&#39;</span>,<span style="color:#e6db74">&#39;i&#39;</span>,<span style="color:#e6db74">&#39;o&#39;</span>,<span style="color:#e6db74">&#39;u&#39;</span>]
</span></span><span style="display:flex;"><span><span style="color:#75715e">#numbers = [&#39;0&#39;,&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39;,&#39;6&#39;,&#39;7&#39;,&#39;8&#39;,&#39;9&#39;]</span>
</span></span><span style="display:flex;"><span>punctuations <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;;&#34;</span>,<span style="color:#e6db74">&#34;&#39;&#34;</span>,<span style="color:#e6db74">&#39;?&#39;</span>,<span style="color:#e6db74">&#39;:&#39;</span>,<span style="color:#e6db74">&#39;!&#39;</span>,<span style="color:#e6db74">&#39;;&#39;</span>,<span style="color:#e6db74">&#39;&#34;&#39;</span>,<span style="color:#e6db74">&#39;.&#39;</span>,<span style="color:#e6db74">&#39;,&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>symbols <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;$&#39;</span>,<span style="color:#e6db74">&#39;[&#39;</span>,<span style="color:#e6db74">&#39;]&#39;</span>,<span style="color:#e6db74">&#39;/&#39;</span>,<span style="color:#e6db74">&#39;%&#39;</span>,<span style="color:#e6db74">&#39;$&#39;</span>,<span style="color:#e6db74">&#39;&amp;&#39;</span>,<span style="color:#e6db74">&#39;(&#39;</span>,<span style="color:#e6db74">&#39;)&#39;</span>,<span style="color:#e6db74">&#39;-&#39;</span>,<span style="color:#e6db74">&#39;_&#39;</span>,<span style="color:#e6db74">&#39;`&#39;</span>,<span style="color:#e6db74">&#39;#&#39;</span>,<span style="color:#e6db74">&#39;@&#39;</span>,<span style="color:#e6db74">&#39;^&#39;</span>,<span style="color:#e6db74">&#39;*&#39;</span>,<span style="color:#e6db74">&#39;+&#39;</span>,<span style="color:#e6db74">&#39;=&#39;</span>,<span style="color:#e6db74">&#39;}&#39;</span>,<span style="color:#e6db74">&#39;{&#39;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;&gt;&#39;</span>,<span style="color:#e6db74">&#39;&lt;&#39;</span>,<span style="color:#e6db74">&#39;~&#39;</span>,<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">&#34;</span>,<span style="color:#e6db74">&#34;|&#34;</span>]
</span></span></code></pre></div><p>Other preprocessing helper functions/ Please, read through to understand what the code does:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Function shifts the columns by a number of step so we can align any character with the character(s) that occur before and after it.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_context</span>(dataframe,column<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Characters&#39;</span>,name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>,n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,fill_value<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;UNK&#39;</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,n_gram<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[column]<span style="color:#f92672">.</span>shift(i, fill_value<span style="color:#f92672">=</span> fill_value) <span style="color:#75715e"># shift down</span>
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[column]<span style="color:#f92672">.</span>shift(<span style="color:#f92672">-</span>i, fill_value<span style="color:#f92672">=</span>fill_value)<span style="color:#75715e"># shift up</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> dataframe
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function typify characters into &#39;alpha&#39;, &#39;dig&#39;, &#39;sym&#39; for letters, numbers, symbols respectively.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_type</span>(char):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> char<span style="color:#f92672">.</span>isalpha():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;a&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">elif</span> char<span style="color:#f92672">.</span>isdigit():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;d&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;s&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function classifies character into &#39;vow&#39;,&#39;con&#39;,&#39;dig&#39;,&#39;punc&#39;,&#39;sign&#39; for vowel, consonant, number, punctuation and sign respectively</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_class</span>(char):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> char<span style="color:#f92672">.</span>isdigit():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;d&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">elif</span> char <span style="color:#f92672">in</span> vowels:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;v&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">elif</span> char <span style="color:#f92672">in</span> punctuations:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;p&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">elif</span> char <span style="color:#f92672">in</span> symbols:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;s&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39;c&#39;</span><span style="color:#75715e"># character here has to be a consonant.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_congruity</span>(dataframe):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># This function checks the character before and after the index character to see if they belong to the</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># same type,class.</span>
</span></span><span style="display:flex;"><span>  dataframe[<span style="color:#e6db74">&#39;is_congruos_type&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;pre-1 type&#39;</span>] <span style="color:#f92672">==</span> dataframe[<span style="color:#e6db74">&#39;post-1 type&#39;</span>]
</span></span><span style="display:flex;"><span>  dataframe[<span style="color:#e6db74">&#39;is_congrous_class&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;pre-1 class&#39;</span>] <span style="color:#f92672">==</span> dataframe[<span style="color:#e6db74">&#39;post-1 type&#39;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> dataframe
</span></span></code></pre></div><p>Now, let&rsquo;s process these characters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train <span style="color:#f92672">=</span> extract_context(train_data<span style="color:#f92672">.</span>copy(), n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>train<span style="color:#f92672">.</span>head()
</span></span></code></pre></div><!-- raw HTML omitted -->
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train<span style="color:#f92672">.</span>tail(<span style="color:#ae81ff">10</span>)
</span></span></code></pre></div><!-- raw HTML omitted -->
<p>Next, we calculate and extract the frequency, prob of the index character, transitional probabilities with neighbouring characters, frequency and probability of whole sequence in the whole sequence. We can consider 3 character sequences and 5 character sequences.</p>
<p>First, we concatenate the sequences appropriately into new columns before computing the frequency of each. For sequences, we can consider 3 types of sequences:</p>
<p>Letter sequences (e.g &rsquo;t&rsquo;,&lsquo;h&rsquo;,&rsquo;e&rsquo; as sequence &rsquo;the&rsquo;)</p>
<p>class sequences (e.g &rsquo;t&rsquo;,&lsquo;h&rsquo;,&rsquo;e&rsquo; as sequence &lsquo;consonant-consonant-vowel&rsquo;)</p>
<p>type sequences (e.g &rsquo;t&rsquo;, &lsquo;h&rsquo;,&rsquo;e&rsquo; as sequence &rsquo;letter-letter-letter&rsquo;)</p>
<p>The most important is the first!</p>
<p>Let&rsquo;s write code for this (I&rsquo;ll leave exhaustive comments)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>char_properties <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Characters&#39;</span>,<span style="color:#e6db74">&#39;class&#39;</span>,<span style="color:#e6db74">&#39;type&#39;</span>] <span style="color:#75715e"># Properties of each character</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_order</span>(index_column<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Characters&#39;</span>,append_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>, n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Function gets the correct order of the characters that appear before and after the index character.</span>
</span></span><span style="display:flex;"><span>  order <span style="color:#f92672">=</span> [<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,n_gram<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)] <span style="color:#f92672">+</span> [index_column] <span style="color:#f92672">+</span>[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,n_gram<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)]
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> order
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This function generates all possible combinations (sequences) between index character and</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># character(s) before and after.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Note: This function is symmetric in action and was built to only consider exactly 1 or 2 characters</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># before and after the index character.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># I did this to reduce the computational complexity. I also only used exactly 2 characters before and after</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># the index character for this training.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_seq_columns</span>(dataframe,column<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Characters&#39;</span>,append_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>,n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>  order <span style="color:#f92672">=</span> get_order(column, append_name, n_gram)
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#print(order)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> n_gram <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>: <span style="color:#75715e"># If we are using just 1 character before and after, shift up by 1 step and down by 1 step</span>
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-1 seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">0</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">1</span>]]
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-1 seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">1</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">2</span>]]
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;whole-seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">0</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">1</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">2</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>: <span style="color:#75715e"># Else shift 2 steps up and then down.</span>
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-1 seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">0</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">2</span>]]
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-2 seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">1</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">0</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">2</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-1 seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">2</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">3</span>]]
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-2 seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">2</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">3</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">4</span>]]
</span></span><span style="display:flex;"><span>    dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;whole-seq </span><span style="color:#e6db74">{</span>append_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[order[<span style="color:#ae81ff">1</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">0</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">2</span>]] <span style="color:#f92672">+</span> \
</span></span><span style="display:flex;"><span>                            dataframe[order[<span style="color:#ae81ff">3</span>]] <span style="color:#f92672">+</span> dataframe[order[<span style="color:#ae81ff">4</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> dataframe
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function calculates the frequency and probability of occurrence of any given column</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># It check the frequency of a character or sequence in the dataset and divides it by the number of samples in dataset or number of unique sequences in corpus.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># e.g how often the sequence &#39;to&#39; occurs in the dataset given the number of unique 2 letter sequences in the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cal_freq_prob</span>(dataframe,column, index<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,return_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, seq<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># group data by the unique values of a column and count their occurrence</span>
</span></span><span style="display:flex;"><span>  freq <span style="color:#f92672">=</span> dict(dataframe<span style="color:#f92672">.</span>groupby(column)[column]<span style="color:#f92672">.</span>count())
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#print(&#39;length of freq keys: &#39;, len(freq.keys()))</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> return_freq: <span style="color:#75715e"># return frequency</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#print(column + &#39;-freq&#39;)</span>
</span></span><span style="display:flex;"><span>    dataframe[column <span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>] <span style="color:#f92672">=</span> dataframe[column]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: int(freq[x]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  num_of_samples <span style="color:#f92672">=</span> len(dataframe) <span style="color:#75715e"># number of samples in dataframe</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> index:  <span style="color:#75715e"># if its the &#39;Characters&#39; column the find the percentage of occurence.</span>
</span></span><span style="display:flex;"><span>    dataframe[column <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;-prob&#39;</span>] <span style="color:#f92672">=</span> dataframe[column]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x : int(freq[x])<span style="color:#f92672">/</span>num_of_samples)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dataframe
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> seq: <span style="color:#75715e"># if column represents a sequence then get the probability of sequence and occurence/number of unique (n_gram)sequence.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># get the number of unique sequences after grouping by sequence column above</span>
</span></span><span style="display:flex;"><span>    num_of_seq <span style="color:#f92672">=</span> len(freq)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#print(total)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Calculate both entities discussed above.</span>
</span></span><span style="display:flex;"><span>    dataframe[column <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;-samprob&#39;</span>] <span style="color:#f92672">=</span> dataframe[column]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: int(freq[x])<span style="color:#f92672">/</span> num_of_seq)
</span></span><span style="display:flex;"><span>    dataframe[column <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;-prob&#39;</span>] <span style="color:#f92672">=</span> dataframe[column]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x : int(freq[x])<span style="color:#f92672">/</span>num_of_samples)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> dataframe
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This function calculates the transitional probability using the formula as discussed above</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function was initially for the words segmentation model but I later generalised the function so it can be used for the sentence  as well.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># given a sequence xyxf, we calculate the trans. prob. for y being the next letter given x, for x being the next letter given &#39;xy&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># and then for &#39;f&#39; being the next letter given &#39;xyx&#39;.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># All the columns ending with -freq suffix and pre/post prefix have already being automatically generated by other functions during</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># processing.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># But they just create various sequence of diff. length given the n_gram: e.g for &#39;xyzf&#39; we have : &#39;xy&#39;,&#39;xyz&#39;,&#39;xyzf&#39; sequences.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cal_transitional_prob</span>(dataframe,index<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Characters&#39;</span>,n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># if we are dealing with the &#39;Characters&#39; column:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> index <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Characters&#39;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> n_gram <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> : <span style="color:#75715e"># if we consider just one character both before and after index character:</span>
</span></span><span style="display:flex;"><span>      dataframe[<span style="color:#e6db74">&#39;trans-pre&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;pre-1 seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span>dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>      dataframe[<span style="color:#e6db74">&#39;trans-post&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;post-1 seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span> dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>: <span style="color:#75715e"># if we consider more than one character</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, n_gram<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">&#39;trans-pre-1&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;pre-1 seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span>dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">&#39;trans-post-1&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;post-1 seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span> dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span>dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> seq -freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dataframe
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>: <span style="color:#75715e"># If we are not dealing with &#39;Characters&#39; column then do this below. Its basically the same code as that above.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> n_gram <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>      dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-pre </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-1 seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span>dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>      dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-post </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-1 seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span> dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,n_gram<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>: <span style="color:#75715e"># if we are dealing with sequences that involve the closest set of characters to the index character.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># for example: in &#39;xyxf&#39;, the closest characters to &#39;x&#39; (3rd one) are &#39;y&#39; and &#39;f&#39;</span>
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span>dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span> dataframe[index<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>: <span style="color:#75715e"># Else, consider the distant characters too</span>
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span>dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>          dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;trans-post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)<span style="color:#f92672">/</span> dataframe[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> seq </span><span style="color:#e6db74">{</span>index<span style="color:#e6db74">}</span><span style="color:#e6db74">-freq&#39;</span>]<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> dataframe
</span></span></code></pre></div><p>Now, we will make use of all the functions (put them all in one function) above to process the data and engineer our features in this format:</p>
<ul>
<li>
<p>Extract and process characters (remove &lsquo;.&rsquo;,&rsquo;,&rsquo; and uppercase etc)</p>
</li>
<li>
<p>Extract properties of each features (e.g. alphabet, digit or symbol etc)</p>
</li>
<li>
<p>calculate the frequency of each character in the corpus.</p>
</li>
<li>
<p>Extract context : shift each character (a new column) by a number of steps so we can extract the character(s) that come before and after it.</p>
</li>
<li>
<p>Calculate the frequency of occurence of the each character with the character(s) that come before and after it in the corpus.</p>
</li>
<li>
<p>Check for congruity: If the characters before index character have the same type with the character after index character, return True otherwise, return false.</p>
</li>
<li>
<p>Calculate the probability of the sequence being a valid subword from the corpus.</p>
</li>
<li>
<p>Calculate the transitional probability of the index character to the next and previous characters. We do this for the characters.</p>
</li>
<li>
<p>Encode columns with class labels (one-hot encoding).</p>
</li>
</ul>
<p>After this processing, we will train with an MLP model for convenience.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Function drops any set of columns we do not want to use for our task after we have computed and extracted the relevant features</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">drop_column</span>(dataframe, pattern): <span style="color:#75715e"># pattern here represents a column name in dataset</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> type(pattern) <span style="color:#f92672">==</span> list: <span style="color:#75715e"># if given a list of columns, do this: delete all.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> pattern:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> dataframe<span style="color:#f92672">.</span>columns:
</span></span><span style="display:flex;"><span>          <span style="color:#66d9ef">if</span> col<span style="color:#f92672">.</span>endswith(i):
</span></span><span style="display:flex;"><span>            dataframe <span style="color:#f92672">=</span> dataframe<span style="color:#f92672">.</span>drop(columns<span style="color:#f92672">=</span>[col])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>: <span style="color:#75715e"># else, delete the one column given</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> dataframe<span style="color:#f92672">.</span>columns:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> col<span style="color:#f92672">.</span>endswith(pattern):
</span></span><span style="display:flex;"><span>          dataframe <span style="color:#f92672">=</span> dataframe<span style="color:#f92672">.</span>drop(columns<span style="color:#f92672">=</span>[pattern])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dataframe
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Now, the main function that ties the whole task together: extract all features of index characters and its context.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_char_dataset</span>(dataframe,char_fill<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;UNK&#39;</span>, class_type_fill <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;UNK&#39;</span>,n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># block of code extractes properties of each character:</span>
</span></span><span style="display:flex;"><span>  dataframe[<span style="color:#e6db74">&#39;class&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;Characters&#39;</span>]<span style="color:#f92672">.</span>apply(get_class)
</span></span><span style="display:flex;"><span>  dataframe[<span style="color:#e6db74">&#39;type&#39;</span>] <span style="color:#f92672">=</span> dataframe[<span style="color:#e6db74">&#39;Characters&#39;</span>]<span style="color:#f92672">.</span>apply(get_type)
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> cal_freq_prob(dataframe, <span style="color:#e6db74">&#39;Characters&#39;</span>,index<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,return_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># block of code extract context and its features</span>
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> extract_context(dataframe, n_gram<span style="color:#f92672">=</span>n_gram,fill_value<span style="color:#f92672">=</span>char_fill)
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> extract_context(dataframe,<span style="color:#e6db74">&#39;class&#39;</span>,<span style="color:#e6db74">&#39;class&#39;</span>,n_gram<span style="color:#f92672">=</span>n_gram,fill_value<span style="color:#f92672">=</span>class_type_fill)
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> extract_context(dataframe,<span style="color:#e6db74">&#39;type&#39;</span>,<span style="color:#e6db74">&#39;type&#39;</span>,n_gram<span style="color:#f92672">=</span>n_gram, fill_value<span style="color:#f92672">=</span>class_type_fill)
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> get_congruity(dataframe)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># block of code generates sequences by concatenating the index character to the &#39;before&#39; and &#39;after&#39; character(s)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># block of code also calculates other properties : transitional prob, prob. of sequence etc</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> process_seq_columns(dataframe, n_gram<span style="color:#f92672">=</span> n_gram) <span style="color:#75715e"># Create pre, post and whole sequences</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Calculate frequency, prob of sequence and transitional probability for each character.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, n_gram <span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#print(&#39;yes&#39;)</span>
</span></span><span style="display:flex;"><span>    dataframe <span style="color:#f92672">=</span> cal_freq_prob(dataframe, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;pre-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq &#39;</span>,return_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,seq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) <span style="color:#75715e">#for presequence</span>
</span></span><span style="display:flex;"><span>    dataframe <span style="color:#f92672">=</span> cal_freq_prob(dataframe, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;post-</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> seq &#39;</span>,return_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,seq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) <span style="color:#75715e"># for post sequence</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> cal_freq_prob(dataframe,<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;whole-seq &#39;</span>,return_freq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,seq<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) <span style="color:#75715e"># for whole sequence with index in middle</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># dataframe = cal_freq_prob(dataframe, &#39;pre-1 seq &#39;,return_freq=True,seq=True) #for presequence</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># dataframe = cal_freq_prob(dataframe, &#39;post-1 seq &#39;,return_freq=True,seq=True) # for post sequence</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># dataframe = cal_freq_prob(dataframe, &#39;whole-seq &#39;,return_freq=True,seq=True) # for whole sequence with index in middle</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># calculate the transitional probabilities of all sequences/character into the character that immediately follows it.</span>
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> cal_transitional_prob(dataframe, <span style="color:#e6db74">&#39;Characters&#39;</span> ,n_gram)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Now we drop all the columns we dont need after we have extracted and calculated the ones we need.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  drop <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> dataframe<span style="color:#f92672">.</span>columns :
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (col<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#39;pre&#39;</span>) <span style="color:#f92672">and</span> col<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;seq &#39;</span>)) <span style="color:#f92672">or</span> (col<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#39;post&#39;</span>) <span style="color:#f92672">and</span> col<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;seq &#39;</span>)):
</span></span><span style="display:flex;"><span>      drop<span style="color:#f92672">.</span>append(col)
</span></span><span style="display:flex;"><span>  drop<span style="color:#f92672">.</span>append(<span style="color:#e6db74">&#39;whole-seq &#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  dataframe <span style="color:#f92672">=</span> drop_column(dataframe,drop)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> dataframe
</span></span></code></pre></div><p>Next, we preprocess the data</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train <span style="color:#f92672">=</span> process_char_dataset(train,n_gram<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><p>Let&rsquo;s look at the final data</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train<span style="color:#f92672">.</span>head()
</span></span></code></pre></div><!-- raw HTML omitted -->
<p>Next, we create our preprocessing transformers that will encode our categorical columns and scale our real valued columms. We will use the MinMax scaler for the real valued columns and the ordinal + one hot encoder for the categorical columns. Scaling is very important for deep learning frameworks as it gives a stable performance.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># We store all categorical features in a list so we can apply the right encoding to them.</span>
</span></span><span style="display:flex;"><span>categorical_columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Characters&#39;</span>, <span style="color:#e6db74">&#39;class&#39;</span>, <span style="color:#e6db74">&#39;type&#39;</span>, <span style="color:#e6db74">&#39;pre-1 &#39;</span>, <span style="color:#e6db74">&#39;post-1 &#39;</span>,<span style="color:#e6db74">&#39;pre-2 &#39;</span>,<span style="color:#e6db74">&#39;post-2 &#39;</span>,
</span></span><span style="display:flex;"><span>       <span style="color:#e6db74">&#39;pre-1 class&#39;</span>, <span style="color:#e6db74">&#39;post-1 class&#39;</span>, <span style="color:#e6db74">&#39;pre-2 class&#39;</span>,<span style="color:#e6db74">&#39;post-2 class&#39;</span>,<span style="color:#e6db74">&#39;pre-1 type&#39;</span>, <span style="color:#e6db74">&#39;post-1 type&#39;</span>,
</span></span><span style="display:flex;"><span>       <span style="color:#e6db74">&#39;pre-2 type&#39;</span>, <span style="color:#e6db74">&#39;post-2 type&#39;</span>,<span style="color:#e6db74">&#39;is_congruos_type&#39;</span>, <span style="color:#e6db74">&#39;is_congrous_class&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define categories that will be used by the Ordinal encoder.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># We add an extra character &#39;,&#39; to the unique values in the &#39;Characters&#39; column so that</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># &#39;Characters&#39;,&#39;pre-1&#39;,&#39;post-1&#39; columns have the same kind of one-hot encoding representation.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Therefore, we want both the &#39;Characters&#39;,&#39;type&#39; and &#39;class&#39; columns to have the same representation</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># as their counterparts.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># It takes a dictionary of the colum to characters to append to represent the null_values</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># So we define this dictionary before the function.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># I make this functionalities as functions so they can be reused downstream if needed.</span>
</span></span><span style="display:flex;"><span>append_chars <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Characters&#39;</span>: <span style="color:#e6db74">&#39;UNK&#39;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;class&#39;</span>: <span style="color:#e6db74">&#39;UNK&#39;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;type&#39;</span>: <span style="color:#e6db74">&#39;UNK&#39;</span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function as described above.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_categories</span>(dataframe,append_chars):
</span></span><span style="display:flex;"><span>  categories <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> cat <span style="color:#f92672">in</span> categorical_columns:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> cat <span style="color:#f92672">in</span> append_chars<span style="color:#f92672">.</span>keys():
</span></span><span style="display:flex;"><span>      values <span style="color:#f92672">=</span> list(dataframe[cat]<span style="color:#f92672">.</span>unique())
</span></span><span style="display:flex;"><span>      values<span style="color:#f92672">.</span>append(append_chars[cat])
</span></span><span style="display:flex;"><span>      categories<span style="color:#f92672">.</span>append(values)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>      categories<span style="color:#f92672">.</span>append(list(dataframe[cat]<span style="color:#f92672">.</span>unique()))
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> categories
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To preprocess the data, we need to process the categorical features and continuous features in different ways</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># so we write two classes that extract the categorical columns and drop the categorical columns so they can be processed</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># differently by the different transformers.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ColumnExtractor</span>(BaseEstimator, TransformerMixin):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> __init__(self,col_extract):
</span></span><span style="display:flex;"><span>    super(ColumnExtractor, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>col_extract <span style="color:#f92672">=</span> col_extract
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fit</span>(self, X, y<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> self
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">transform</span>(self,X):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> X[self<span style="color:#f92672">.</span>col_extract]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ColumnDropper</span>(BaseEstimator,TransformerMixin):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> __init__(self,col_drop):
</span></span><span style="display:flex;"><span>    super(ColumnDropper, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>col_drop <span style="color:#f92672">=</span> col_drop
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fit</span>(self, X, y<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> self
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">transform</span>(self,X):
</span></span><span style="display:flex;"><span>    Xt <span style="color:#f92672">=</span> X<span style="color:#f92672">.</span>drop(columns<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>col_drop)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> Xt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># function saves models to file.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">save_to_file</span>(obj,file_path):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">with</span> open(file_path,<span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>    pickle<span style="color:#f92672">.</span>dump(obj,f)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># function loads saved models from file.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load</span>(file_path):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">with</span> open(file_path, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>    obj <span style="color:#f92672">=</span> pickle<span style="color:#f92672">.</span>load(f)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> obj
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Function preprocesses and transforms data into sth acceptable by our deep learning model.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># we then store the fitted transformer to our drive so it can always be used anytime we want to segment raw text.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocess_data</span>(dataframe,cat_columns,cat_values<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,file_path<span style="color:#f92672">=</span>FILE_PATH,pipe_name<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,save<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># define custom Transformers</span>
</span></span><span style="display:flex;"><span>  cat_transformer <span style="color:#f92672">=</span> ColumnExtractor(cat_columns) <span style="color:#75715e"># extract categorical columns</span>
</span></span><span style="display:flex;"><span>  cont_transformer <span style="color:#f92672">=</span> ColumnDropper(cat_columns) <span style="color:#75715e"># drop cat columns</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> cat_values:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># define Scaler transformers appropriately</span>
</span></span><span style="display:flex;"><span>    scaler_pipeline <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;transformer&#39;</span>, cont_transformer),(<span style="color:#e6db74">&#39;scaler&#39;</span>,MinMaxScaler())])
</span></span><span style="display:flex;"><span>    encoder_pipeline <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;transformer&#39;</span>, cat_transformer),
</span></span><span style="display:flex;"><span>                    (<span style="color:#e6db74">&#39;label_encoder&#39;</span>,OrdinalEncoder(categories<span style="color:#f92672">=</span>cat_values)),(<span style="color:#e6db74">&#39;one_hot&#39;</span>,OneHotEncoder())])
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># define Scaler transformers appropriately</span>
</span></span><span style="display:flex;"><span>    scaler_pipeline <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;transformer&#39;</span>, cont_transformer),(<span style="color:#e6db74">&#39;scaler&#39;</span>,MinMaxScaler())])
</span></span><span style="display:flex;"><span>    encoder_pipeline <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;transformer&#39;</span>, cat_transformer),
</span></span><span style="display:flex;"><span>                    (<span style="color:#e6db74">&#39;label_encoder&#39;</span>,OrdinalEncoder()),(<span style="color:#e6db74">&#39;one_hot&#39;</span>,OneHotEncoder())])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># create a pipeline that transforms the data simultaeneously</span>
</span></span><span style="display:flex;"><span>  feature_pipeline <span style="color:#f92672">=</span> FeatureUnion([(<span style="color:#e6db74">&#39;scaler_p&#39;</span>,scaler_pipeline),(<span style="color:#e6db74">&#39;encoder_p&#39;</span>,encoder_pipeline)])
</span></span><span style="display:flex;"><span>  train_x <span style="color:#f92672">=</span> feature_pipeline<span style="color:#f92672">.</span>fit_transform(dataframe)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># save transformer to file.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> save <span style="color:#f92672">and</span> pipe_name:
</span></span><span style="display:flex;"><span>    file_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(file_path,pipe_name)
</span></span><span style="display:flex;"><span>    save_to_file(feature_pipeline,file_path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> save <span style="color:#f92672">and</span> (<span style="color:#f92672">not</span> pipe_name):
</span></span><span style="display:flex;"><span>    file_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(file_path, <span style="color:#e6db74">&#39;demo&#39;</span>)
</span></span><span style="display:flex;"><span>    save_to_file(feature_pipeline, file_path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> train_x , feature_pipeline
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>categories <span style="color:#f92672">=</span> get_categories(train,append_chars)
</span></span><span style="display:flex;"><span>train , transformer <span style="color:#f92672">=</span> preprocess_data(train, categorical_columns,                       categories, pipe_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;char_pipeline_transformer&#39;</span>)
</span></span><span style="display:flex;"><span>train
</span></span></code></pre></div><pre tabindex="0"><code>&lt;3088940x352 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
	with 116829993 stored elements in Compressed Sparse Row format&gt;
</code></pre><p>We have a sparse matrix because of the one hot encoding of a categorical variables with a lot of unique values.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># We convert the target data into categorical data( one hot encoding) for training our deep learning model</span>
</span></span><span style="display:flex;"><span>target_data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>to_categorical(target_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># we split data into train and test set (0.8:0.2)</span>
</span></span><span style="display:flex;"><span>X_train, X_test , y_train, y_test <span style="color:#f92672">=</span> train_test_split(train, target_data,test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train, X_test
</span></span></code></pre></div><pre tabindex="0"><code>(&lt;2471152x352 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
 	with 93445997 stored elements in Compressed Sparse Row format&gt;,
 &lt;617788x352 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
 	with 23383996 stored elements in Compressed Sparse Row format&gt;)
</code></pre><h2 id="train-model">Train Model</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># define model, set batch size and number of epochs for training.</span>
</span></span><span style="display:flex;"><span>batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>input_dim <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#75715e"># set the input dimensions for the neural network</span>
</span></span><span style="display:flex;"><span>output_dim <span style="color:#f92672">=</span> target_data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#75715e"># set the output_dim for the neural network</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This function creates a full model.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_model</span>(input_dim,first_layer_units<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>, hidden_layer_units<span style="color:#f92672">=</span><span style="color:#ae81ff">700</span>,output_units<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>):
</span></span><span style="display:flex;"><span>  model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>  model<span style="color:#f92672">.</span>add(Dense(first_layer_units,input_dim<span style="color:#f92672">=</span>input_dim ,activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_uniform&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  model<span style="color:#f92672">.</span>add(Dense(hidden_layer_units, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_uniform&#39;</span>))
</span></span><span style="display:flex;"><span>  model<span style="color:#f92672">.</span>add(Dense(hidden_layer_units, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_uniform&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  model<span style="color:#f92672">.</span>add(Dense(output_units, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span><span style="display:flex;"><span>  model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>losses<span style="color:#f92672">.</span>CategoricalCrossentropy(), optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#model.summary()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> create_model(input_dim,<span style="color:#ae81ff">1000</span>,<span style="color:#ae81ff">700</span>,output_dim)
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>summary()
</span></span></code></pre></div><p>``
Model: &ldquo;sequential&rdquo;</p>
<hr>
<h1 id="layer-type----------------output-shape--------------param-">Layer (type)                Output Shape              Param #</h1>
<p>dense (Dense)               (None, 1000)              353000</p>
<p>dense_1 (Dense)             (None, 700)               700700</p>
<p>dense_2 (Dense)             (None, 700)               490700</p>
<p>dense_3 (Dense)             (None, 4)                 2804</p>
<p>=================================================================
Total params: 1547204 (5.90 MB)
Trainable params: 1547204 (5.90 MB)
Non-trainable params: 0 (0.00 Byte)</p>
<hr>
<pre tabindex="0"><code>

```python
es = EarlyStopping(monitor=&#39;val_loss&#39;, mode=&#39;min&#39;, verbose=1, patience=5)

# Schedule learning rate when you hit a plateau. The learning rate drops to a smaller value when performance hits a plateau.
lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.1, patience=5, min_delta=1E-7)

history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,
                    validation_data=(X_test, y_test),callbacks=[es,lr])
</code></pre><pre tabindex="0"><code>Epoch 1/10
4827/4827 [==============================] - 77s 14ms/step - loss: 0.2218 - accuracy: 0.9163 - val_loss: 0.1808 - val_accuracy: 0.9346 - lr: 0.0010
Epoch 2/10
4827/4827 [==============================] - 63s 12ms/step - loss: 0.1707 - accuracy: 0.9364 - val_loss: 0.1738 - val_accuracy: 0.9378 - lr: 0.0010
Epoch 3/10
4827/4827 [==============================] - 58s 11ms/step - loss: 0.1563 - accuracy: 0.9415 - val_loss: 0.1636 - val_accuracy: 0.9412 - lr: 0.0010
Epoch 4/10
4827/4827 [==============================] - 58s 11ms/step - loss: 0.1473 - accuracy: 0.9445 - val_loss: 0.1614 - val_accuracy: 0.9433 - lr: 0.0010
Epoch 5/10
4827/4827 [==============================] - 60s 12ms/step - loss: 0.1408 - accuracy: 0.9466 - val_loss: 0.1625 - val_accuracy: 0.9435 - lr: 0.0010
Epoch 6/10
4827/4827 [==============================] - 58s 11ms/step - loss: 0.1358 - accuracy: 0.9482 - val_loss: 0.1661 - val_accuracy: 0.9437 - lr: 0.0010
Epoch 7/10
4827/4827 [==============================] - 61s 11ms/step - loss: 0.1321 - accuracy: 0.9494 - val_loss: 0.1649 - val_accuracy: 0.9442 - lr: 0.0010
Epoch 8/10
4827/4827 [==============================] - 58s 11ms/step - loss: 0.1286 - accuracy: 0.9503 - val_loss: 0.1674 - val_accuracy: 0.9444 - lr: 0.0010
Epoch 9/10
4827/4827 [==============================] - 63s 12ms/step - loss: 0.1262 - accuracy: 0.9511 - val_loss: 0.1701 - val_accuracy: 0.9446 - lr: 0.0010
Epoch 9: early stopping
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pyplot<span style="color:#f92672">.</span>plot(history<span style="color:#f92672">.</span>history[<span style="color:#e6db74">&#39;loss&#39;</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>pyplot<span style="color:#f92672">.</span>plot(history<span style="color:#f92672">.</span>history[<span style="color:#e6db74">&#39;val_loss&#39;</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;test&#39;</span>)
</span></span><span style="display:flex;"><span>pyplot<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>pyplot<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><!-- raw HTML omitted -->
<p>Here, we see that the model performed very well and generalized pretty well to the data. However, its most likely that the performance of the model will differ based on the length of the full text it was given because of the features that were manually extracted for the model that took length (number of samples) into account.</p>
<p>Let&rsquo;s save the model to file memory.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;word_segmentor&#39;</span>
</span></span><span style="display:flex;"><span>model_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(FILE_PATH,model_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>save(model_path)
</span></span></code></pre></div><p>Whoops! That was a whole lot. We finally have a trained model for word segmentation with pretty good accuracy! Thats&rsquo; all for word segmentation. To see and appreciate the output of this model, check out the <!-- raw HTML omitted -->Part 2 here<!-- raw HTML omitted -->.</p>
<p>Thank you for your time and see you soon!!</p>

</div>

</section>
<footer id="footer">
    <strong></strong>
    <div class="social">
        &nbsp;
<a href="https://github.com/pauljeffrey" target="_blank" rel="me" title="Github" referrerpolicy="no-referrer">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
	stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
	<path
		d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
	</path>
</svg>
</a>
&nbsp;&nbsp;
<a href="drjeffreypaul@gmail.com" target="_blank" rel="me" title="Email" referrerpolicy="no-referrer">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
	stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
	<path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
	<polyline points="22,6 12,13 2,6"></polyline>
</svg>
</a>
&nbsp;&nbsp;
<a href="https://twitter.com/Jeffreypaul_" target="_blank" rel="me" title="Twitter" referrerpolicy="no-referrer">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
	stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
	<path
		d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z">
	</path>
</svg>
</a>
&nbsp;&nbsp;
<a href="https://www.linkedin.com/in/jeffreyotoibhi/" target="_blank" rel="me" title="Linkedin" referrerpolicy="no-referrer">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
	stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
	<path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
	<rect x="2" y="9" width="4" height="12"></rect>
	<circle cx="4" cy="4" r="2"></circle>
</svg>
</a>
&nbsp;
    </div><strong></strong>
    <p style="color:grey;"> 2024 Jeffrey Paul.  <a href="https://creativecommons.org/licenses/by/4.0/">Some rights reserved</a>.</p>
</footer>
</div>
    </body>
</html>
